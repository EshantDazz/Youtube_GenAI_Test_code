<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Langchain Fallbacks: Graceful Degradation for LLM Applications</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: #0a192f;
            --secondary-color: #64ffda;
            --accent-color: #f76c6c;
            --background-color: #0a192f;
            --text-color: #8892b0;
            --light-text-color: #ccd6f6;
            --code-background: #1e1e1e;
            --code-text-color: #d4d4d4;
        }
        body {
            font-family: 'Inter', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            margin: 0;
            padding: 0;
            background-color: var(--background-color);
        }
        header {
            background-color: var(--primary-color);
            color: var(--light-text-color);
            text-align: center;
            padding: 4rem 1rem;
            position: relative;
            overflow: hidden;
        }
        header::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: linear-gradient(45deg, #0a192f, #112240);
            opacity: 0.8;
            z-index: 0;
        }
        header h1 {
            position: relative;
            z-index: 1;
            font-weight: 700;
            font-size: 3rem;
            margin: 0;
            letter-spacing: -1px;
        }
        main {
            max-width: 1000px;
            margin: 4rem auto;
            padding: 0 2rem;
        }
        .course-module {
            background-color: #112240;
            border-radius: 8px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
            margin-bottom: 2rem;
            overflow: hidden;
            transition: all 0.3s ease-in-out;
        }
        .course-module:hover {
            box-shadow: 0 15px 40px rgba(100, 255, 218, 0.1);
            transform: translateY(-5px);
        }
        .module-header {
            background-color: #1d2d50;
            color: var(--secondary-color);
            padding: 1.5rem 2rem;
            font-size: 1.2rem;
            font-weight: 600;
        }
        .module-content {
            padding: 2rem;
        }
        .module-content p {
            margin-bottom: 1rem;
            font-size: 1rem;
            color: var(--light-text-color);
        }
        .module-content h2 {
            color: var(--secondary-color);
            font-size: 1.5rem;
            margin-top: 2rem;
            margin-bottom: 1rem;
        }
        .module-content h3 {
            color: var(--light-text-color);
            font-size: 1.2rem;
            margin-top: 1.5rem;
            margin-bottom: 0.5rem;
        }
        ul {
            padding-left: 2rem;
            color: var(--light-text-color);
        }
        pre {
            background-color: var(--code-background);
            border-radius: 8px;
            padding: 1.5rem;
            overflow-x: auto;
            border: 1px solid #3a3a3a;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        code {
            font-family: 'Courier New', Courier, monospace;
            color: var(--code-text-color);
            font-size: 0.9rem;
        }
        .code-block {
            position: relative;
            margin: 2rem 0;
        }
        .code-block::before {
            content: 'Python';
            position: absolute;
            top: -10px;
            left: 10px;
            background-color: var(--secondary-color);
            color: var(--primary-color);
            padding: 0 10px;
            border-radius: 4px;
            font-size: 0.8rem;
            font-weight: bold;
        }
        .keyword { color: #569cd6; }
        .string { color: #ce9178; }
        .function { color: #dcdcaa; }
        .class { color: #4ec9b0; }
        .comment { color: #6a9955; }
    </style>
</head>
<body>
    <header>
        <h1>Langchain Fallbacks: Graceful Degradation for LLM Applications</h1>
    </header>
    <main>
        <div class="course-module">
            <div class="module-header">Introduction</div>
            <div class="module-content">
                <p>In the world of Large Language Models (LLMs), unexpected issues can arise. These might include API downtime, rate limits, or model-specific errors. To ensure your LLM applications function reliably in production, Langchain introduces the concept of fallbacks, a mechanism for graceful degradation.</p>
            </div>
        </div>

        <div class="course-module">
            <div class="module-header">What are Fallbacks?</div>
            <div class="module-content">
                <p>Fallbacks provide alternative plans when your primary LLM encounters problems. They allow you to specify a sequence of LLMs to try in case the first one fails. This ensures continuity in your application's functionality, even when the initial LLM isn't available.</p>
            </div>
        </div>

        <div class="course-module">
            <div class="module-header">Understanding the Code Example</div>
            <div class="module-content">
                <p>The following code snippet demonstrates how to implement fallbacks in Langchain:</p>
                <div class="code-block">
                    <pre><code><span class="keyword">from</span> langchain_nvidia_ai_endpoints <span class="keyword">import</span> ChatNVIDIA
<span class="keyword">from</span> langchain_groq <span class="keyword">import</span> ChatGroq
<span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> StrOutputParser
<span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate

llm_nvidea = ChatNVIDIA(model=<span class="string">"mistralai/mixtral-8x22b-instruct-v0.1"</span>)  <span class="comment"># NVIDIA LLM</span>
llm_groqai = ChatGroq(model=<span class="string">"llama3-70b-8192"</span>)  <span class="comment"># Groq LLM</span>

llm = llm_groqai.with_fallbacks([llm_nvidea])  <span class="comment"># Create fallback chain with Groq as primary, NVIDIA as fallback</span>

llm.invoke(<span class="string">"Hello"</span>)  <span class="comment"># Send the prompt "Hello" to the fallback chain</span></code></pre>
                </div>

                <h2>Explanation:</h2>
                <h3>1. LLM Instances:</h3>
                <ul>
                    <li><code>llm_nvidea</code>: This line creates an instance of the <code>ChatNVIDIA</code> class, connecting to the NVIDIA LLM with the specified model ("mistralai/mixtral-8x22b-instruct-v0.1").</li>
                    <li><code>llm_groqai</code>: Similarly, this creates an instance of the <code>ChatGroq</code> class for the Groq LLM ("llama3-70b-8192").</li>
                </ul>

                <h3>2. Creating the Fallback Chain:</h3>
                <ul>
                    <li><code>llm.with_fallbacks([llm_nvidea])</code>: Here's the key part. We use the <code>with_fallbacks</code> method on the <code>llm_groqai</code> instance. This method takes a list of fallback LLMs (<code>[llm_nvidea]</code>) as an argument. It creates a new <code>RunnableWithFallbacks</code> object that attempts to execute <code>llm_groqai</code> first. If <code>llm_groqai</code> fails, it tries <code>llm_nvidea</code> in sequence.</li>
                </ul>

                <h3>3. Invoking the Fallback Chain:</h3>
                <ul>
                    <li><code>llm.invoke("Hello")</code>: This line calls the <code>invoke</code> method on the fallback chain (<code>llm</code>). It sends the prompt "Hello" to the chain. The chain will first try to execute the prompt with <code>llm_groqai</code>. If successful, it will return the response from <code>llm_groqai</code>. However, if <code>llm_groqai</code> encounters an error, the chain will gracefully fall back to <code>llm_nvidea</code> and attempt to send the prompt there.</li>
                </ul>
            </div>
        </div>

        <div class="course-module">
            <div class="module-header">Benefits of Fallbacks</div>
            <div class="module-content">
                <h3>Improved Robustness:</h3>
                <p>Fallbacks enhance your application's resilience by providing a backup plan when the primary LLM fails. This ensures continued functionality even during LLM issues.</p>

                <h3>Flexibility:</h3>
                <p>You can define fallback sequences tailored to specific scenarios. For instance, you might have a fallback to a model with a longer context window if the primary model struggles with long inputs.</p>

                <h3>Error Handling:</h3>
                <p>Fallbacks often integrate with error handling mechanisms, allowing you to capture errors from the primary LLM and potentially log them for troubleshooting.</p>
            </div>
        </div>

        <div class="course-module">
            <div class="module-header">Conclusion</div>
            <div class="module-content">
                <p>Langchain fallbacks are a valuable tool for building reliable LLM applications. By incorporating fallbacks, you can mitigate the impact of LLM-related disruptions and provide a smoother user experience.</p>
            </div>
        </div>
    </main>

    <footer style="text-align: center; padding: 2rem 0; color: var(--light-text-color);">
        <p>&copy; 2024 Langchain Fallbacks Tutorial. All rights reserved.</p>
    </footer>

</body>
</html>