{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'runnable' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain_core\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrunnables\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhistory\u001b[39;00m \u001b[39mimport\u001b[39;00m RunnableWithMessageHistory\n\u001b[1;32m      4\u001b[0m with_message_history \u001b[39m=\u001b[39m RunnableWithMessageHistory(\n\u001b[1;32m      5\u001b[0m     \u001b[39m# The underlying runnable\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     runnable,  \n\u001b[1;32m      7\u001b[0m     \u001b[39m# A function that takes in a session id and returns a memory object\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     get_session_history,  \n\u001b[1;32m      9\u001b[0m     \u001b[39m# Other parameters that may be needed to align the inputs/outputs\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[39m# of the Runnable with the memory object\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m  \n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m with_message_history\u001b[39m.\u001b[39minvoke(\n\u001b[1;32m     15\u001b[0m     \u001b[39m# The same input as before\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mability\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mmath\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mWhat does cosine mean?\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     config\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mconfigurable\u001b[39m\u001b[39m\"\u001b[39m: {\u001b[39m\"\u001b[39m\u001b[39msession_id\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mabc123\u001b[39m\u001b[39m\"\u001b[39m}},\n\u001b[1;32m     20\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'runnable' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    # The underlying runnable\n",
    "    runnable,  \n",
    "    # A function that takes in a session id and returns a memory object\n",
    "    get_session_history,  \n",
    "    # Other parameters that may be needed to align the inputs/outputs\n",
    "    # of the Runnable with the memory object\n",
    "    ...  \n",
    ")\n",
    "\n",
    "with_message_history.invoke(\n",
    "    # The same input as before\n",
    "    {\"ability\": \"math\", \"input\": \"What does cosine mean?\"},\n",
    "    # Configuration specifying the `session_id`,\n",
    "    # which controls which conversation to load\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable_with_history = RunnableWithMessageHistory(\n",
    "    model,\n",
    "    get_session_history,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from operator import itemgetter\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('/Users/eshantdas/Desktop/Youtube/Youtube_GenAI_Test_code/myenv/.env')\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(\n",
    "    temperature=0,\n",
    "    model=\"llama3-70b-8192\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "mom=ConversationBufferWindowMemory(k=2)\n",
    "\n",
    "\n",
    "def get_session_history(session_id):\n",
    "    return SQLChatMessageHistory(session_id, \"sqlite:///memory.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable_with_history = RunnableWithMessageHistory(\n",
    "    model,\n",
    "    get_session_history,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eshantdas/Desktop/Youtube/Youtube_GenAI_Test_code/myenv/lib/python3.12/site-packages/langchain_community/chat_message_histories/sql.py:140: LangChainDeprecationWarning: `connection_string` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. Use Use connection instead instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry, but I don't know your name. I'm a large language model, I don't have the ability to know personal information about you unless you tell me. I'm a new conversation each time you interact with me, so I don't retain any information from previous conversations. If you'd like to tell me your name, I'd be happy to chat with you!\", response_metadata={'token_usage': {'completion_tokens': 79, 'prompt_tokens': 15, 'total_tokens': 94, 'completion_time': 0.239055044, 'prompt_time': 0.004181699, 'queue_time': None, 'total_time': 0.243236743}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_87cbfbbc4d', 'finish_reason': 'stop', 'logprobs': None}, id='run-7240f357-ec1c-49e1-8e08-6e7bbac4f399-0', usage_metadata={'input_tokens': 15, 'output_tokens': 79, 'total_tokens': 94})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_with_history.invoke(\n",
    "    [HumanMessage(content=\"whats my name?\")],\n",
    "    config={\"configurable\": {\"session_id\": \"1\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Eshant! I'll make sure to address you by your name from now on. How's your day going so far?\", response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 110, 'total_tokens': 142, 'completion_time': 0.09665643, 'prompt_time': 0.015123186, 'queue_time': None, 'total_time': 0.111779616}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None}, id='run-77e30947-3a05-42a1-9feb-395c8833f984-0', usage_metadata={'input_tokens': 110, 'output_tokens': 32, 'total_tokens': 142})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_with_history.invoke(\n",
    "    [HumanMessage(content=\"My name is Eshant?\")],\n",
    "    config={\"configurable\": {\"session_id\": \"1\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I remember! Your name is Eshant!', response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 156, 'total_tokens': 167, 'completion_time': 0.031543379, 'prompt_time': 0.023106452, 'queue_time': None, 'total_time': 0.054649831}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_87cbfbbc4d', 'finish_reason': 'stop', 'logprobs': None}, id='run-391a8294-1c98-459a-b02d-f4e6b9514faa-0', usage_metadata={'input_tokens': 156, 'output_tokens': 11, 'total_tokens': 167})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_with_history.invoke(\n",
    "    [HumanMessage(content=\"whats my name?\")],\n",
    "    config={\"configurable\": {\"session_id\": \"1\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_function(text):\n",
    "    return len(text)\n",
    "\n",
    "\n",
    "RUN=RunnableLambda(length_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RUN.invoke(\"sdg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eshantdas/Desktop/Youtube/Youtube_GenAI_Test_code/myenv/lib/python3.12/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'baz'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def f(x: str) -> str:\n",
    "    return x + \"a\"\n",
    "\n",
    "def g(x: str) -> str:\n",
    "    return x + \"z\"\n",
    "\n",
    "runnable = RunnableLambda(f) | g\n",
    "as_tool = runnable.as_tool()\n",
    "as_tool.invoke(\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10 Eshant'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a RunnableLambda\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def add_one(x: int) -> int:\n",
    "    return x + 1\n",
    "\n",
    "\n",
    "def multiply_two(a:int)->int:\n",
    "    return a*2\n",
    "\n",
    "def string_converstion(a:int)->str:\n",
    "    return str(a)+\" Eshant\"\n",
    "\n",
    "runnable = RunnableLambda(add_one)\n",
    "bunnable=RunnableLambda(multiply_two)\n",
    "tunnable=RunnableLambda(string_converstion)\n",
    "\n",
    "\n",
    "chain=runnable | bunnable |  tunnable\n",
    "\n",
    "chain.invoke(4)\n",
    "\n",
    "# runnable.invoke(1) # returns 2\n",
    "# runnable.batch([1, 2, 3]) # returns [2, 3, 4]\n",
    "\n",
    "# # Async is supported by default by delegating to the sync implementation\n",
    "# await runnable.ainvoke(1) # returns 2\n",
    "# await runnable.abatch([1, 2, 3]) # returns [2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
